{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Simple Prompt Engineering Examples Using ChatGPT\n",
    "\n",
    "Welcome! This notebook is meant to show some simple prompt engineering examples for those just getting started in the field. We will look at four common tasks associated with typical prompt engineering job requirements to get you on the road to becoming an effective developer:\n",
    "\n",
    "- Content Generation\n",
    "- Content Summariziation\n",
    "- Language Translation\n",
    "- Content Automation\n",
    "\n",
    "There are a couple of things to consider as we explore these concepts:\n",
    "First, we are limiting ourselves to exclusively using OpenAI's API even though there might be better alternatives out there to keep things easy to impelement. \n",
    "Second, You will need an OpenAI API key to do these lessons. They give you a $5 credit when you sign up but IT CAN COST MONEY if you aren't careful. \n",
    "Just be aware of your usage patterns and you will be fine. You can sign up for your API access here: https://platform.openai.com/ \n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Generation\n",
    "Assume we work for a book company and they are looking at expanding into the children book market. They don't want to invest a lot of money in authors before they have tested the waters a bit. That's where we come in; our first task is to write a prompt to create a kids short story. The customer wants us to generate a story and make sure the AI outputs an HTML table with the names of the characters from the story and their role in the story so they can put it up on their website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once upon a time, in a far away kingdom there lived a young princess named Aurora. She was known for her beauty and kindness, and everyone in the kingdom loved her dearly. Despite being the daughter of a powerful king, Aurora had a gentle soul and always showed compassion to those around her. \n",
      "\n",
      "One day, the king and queen decided to throw a grand banquet to celebrate their daughter's birthday. The entire kingdom was invited, but there were two special guests who had been invited – two fairies from the magical realm beyond the castle walls. \n",
      "\n",
      "The first fairy was Flora, an old wise woman with magical powers that could make plants grow with just one touch of her staff. The second fairy was Fauna, a mischievous sprite who delighted in causing trouble among mortals. Despite their differences, they both shared one thing - they were both devoted to Aurora and wanted nothing more than to make her happy on her special day. \n",
      "\n",
      "When the feast began, all eyes were on Aurora as she entered the room with grace and poise befitting a princess. All of the guests marveled at her beauty and wished for her happiness on this day of celebration. However, it soon became apparent that something was wrong - Aurora did not seem happy at all! \n",
      "\n",
      "The King asked what was wrong and Aurora explained that she wanted nothing more than true love but had yet to find it in this kingdom or any other. As she said these words, Flora stepped forward and presented Aurora with an enchanted rosebush that would never lose its petals nor fade in color until true love found her. With tears of joy streaming down their faces, everyone in attendance thanked Flora for such a beautiful gift as they watched Aurora take hold of the rosebush with tender care. \n",
      "\n",
      "Fauna then stepped forward with a mischievous glint in his eyes as he handed Aurora an old book filled with stories about brave knights from distant lands on daring adventures to save damsels in distress - adventures exactly like hers! \n",
      "Aurora opened up the book with curiosity as Fauna whispered into her ear “Your adventure awaits you…” before magically disappearing without another word spoken between them. \n",
      "\n",
      "With newfound courage ignited by Fauna's words ringing through her mind, Aurora vowed to leave home and find true love no matter what challenges lay ahead along the way - all while holding onto the enchanted rosebush given by Flora as evidence that true love will eventually come whenever it is meant to be found.  \n",
      "\n",
      "Characters and Roles: \n",
      "\n",
      " <table>\n",
      "<tr> <th>Character</th> <th>Role</th></tr>\n",
      "<tr><td>Aurora</td><td>Young princess looking for true love.</td></tr>  \n",
      "<tr><td>Flora</td><td>Old wise woman with magical powers.</td></tr>  \t\t\t\t\t\t\t\t\t\t    <tr><td>Fauna</td><td>Mischievous sprite.</td></tr>  \t    <tr><td>King & Queen </td><td>Parents of Princess Aurora.</td></tr>   </table\n"
     ]
    }
   ],
   "source": [
    "# import our packages\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# grab our API key from our environment variables\n",
    "# NOTE: if you don't have an environment variable set, you can just paste your key in directly by modifying the line below and setting your openai_key to your key\n",
    "# like this: openai_key = \"your key goes here\"\n",
    "openai_key = os.getenv('OPENAI_KEY')\n",
    "\n",
    "openai.api_key = openai_key\n",
    "\n",
    "# craft our prompt - this is the text that the AI will use to generate the content\n",
    "# In this example we use the persona feature to give the AI a little bit of context about the type of content we want it to generate\n",
    "# Specifically we want it to be a children story teller generate content in the style of Hans Christian Andersen\n",
    "# This sets the tone and style of the content we want to generate\n",
    "# Next, we give the AI some direction about the type of content we want it to generate to set the \"boundaries\" of the content - these are typically given to us by the client\n",
    "#\n",
    "# Now we deal with the output\n",
    "# We clearly indicate where the story should go and where the character and role table should go to make it easy to parse out the content\n",
    "prompt = \"\"\"\n",
    "Act as a children story teller in the style of Hans Christian Andersen using the following process:\n",
    "1. Make the story no more than 1000 words.\n",
    "2. Create a story that begins with an opening scene that captures the reader's imagination. \n",
    "3. Set the scene by providing a detailed description of the setting and atmosphere, including the time of day, the weather, and any other relevant details that help to immerse the reader in the story. \n",
    "4. Introduce the minor characters in the story, providing enough detail about each character to make them interesting and memorable. \n",
    "5. Introduce the main character of the story, describing their physical appearance in detail and giving some insight into their personality and motivations. \n",
    "6. Make sure that the story has a clear plot and a satisfying resolution, and that the themes explored in the story are appropriate for a young audience. \n",
    "7. Finally, be sure to use vivid language and imagery to bring the story to life and engage the reader's imagination. \n",
    "\n",
    "The story can be about anything you want. Be creative!\n",
    "\n",
    "When you have given me the story, then produce a HTML table with the names of the characters from the story and their role in the story.\n",
    "\n",
    "Story: <story goes here>\n",
    "\n",
    "Characters and Roles: <HTML table goes here>\n",
    "\n",
    "\"\"\"\n",
    "# Now we use the completion.create() method to generate the content and things really get interesting. See my comments on each of the parameters below\n",
    "response = openai.Completion.create(\n",
    "    # This is the model we want to use to generate the content - in this case we are using a ChatGPT 3.5 model because it is cheaper to use than the GPT-4 model\n",
    "    # Useful for prototyping and testing then using the GPT-4 model for later iterations\n",
    "    # At the time of this writing, for input the GPT-3.5 model costs $0.0015 per 1000 tokens and the GPT-4 model costs $0.03 per 1000 tokens; for output the \n",
    "    # GPT-3.5 model costs $0.002 per 1000 tokens and the GPT-4 model costs $0.06 per 1000 tokens\n",
    "    # Quite a cost differential between the two models so start cheap to prototype and test and then use the GPT-4 model for later on\n",
    "    model=\"text-davinci-003\",  \n",
    "\n",
    "    # This is the prompt we created above\n",
    "    prompt=prompt,  \n",
    "\n",
    "    # This is the temperature parameter - it controls the randomness of the output or, put another way, how \"creative\" the AI is\n",
    "    # The number can be between 0 and 1 - the closer to 0 the less \"creative\" the AI is and as the number approaches 1 the more \"creative\" the AI is\n",
    "    # Since we are creating children's stories we want the AI to be more creative so we set the temperature to 0.7\n",
    "    # If we were creating something like a legal document we would want the AI to be less creative so we would set the temperature to 0.2 for example\n",
    "    temperature=0.7,  \n",
    "\n",
    "    # This is the max_tokens parameter - it controls the length of the output\n",
    "    # To quote OpenAI: \"You can think of tokens as pieces of words, where 1,000 tokens is about 750 words.\"\n",
    "    # our prompt is 1000 words so we set the max_tokens to 2000 to give the AI enough room to generate the content\n",
    "    # But small enough to keep the cost down\n",
    "    max_tokens=2000,  \n",
    "\n",
    "    # This is the top_p parameter - it controls the range of words chosen for the output\n",
    "    # The values are from 0 to 1 - the closer to 0 the less diverse the output and the closer to 1 the more diverse the output\n",
    "    # For example, if we set top_p to 0.5 then the AI will only use the top 50% of the most likely words\n",
    "    # But, if we set top_p to 1.0 then the AI will use all of the words\n",
    "    # Since we are creating children's stories we want the AI to be more diverse so we set the top_p to 1.0\n",
    "    # If we were creating something like a legal document we would want the AI to be less diverse so we would set the top_p to 0.5 or less, for example\n",
    "    top_p=1,  \n",
    "\n",
    "    # This is the frequency_penalty parameter - this parameter is used to discourage the model from repeating the same words or phrases too frequently within the generated text.\n",
    "    # A higher frequency_penalty value will result in the model being more conservative in its use of repeated words. \n",
    "    # The values are from -2.0 to 2.0 - the closer to -2.0 the more likely the AI will repeat the same words and the closer to 2.0 the less likely the AI will repeat the same words\n",
    "    # Typical setting for this parameter is 0.0 or to 1 for eliminating repetition in output. We will set ours to 0.5\n",
    "    frequency_penalty=0.5,  \n",
    "\n",
    "    # This is the presence_penalty parameter - this parameter is used to encourage the model to include a diverse range of words in the generated text. \n",
    "    # A higher presence_penalty value will result in the model being more likely to generate words that have not yet been included in the generated text.\n",
    "    # The values are from -2.0 to 2.0 - the closer to -2.0 the more likely the AI will repeat the same words and the closer to 2.0 the more likely to include words not used before\n",
    "    # As with the frequency_penalty parameter, typical setting for this parameter is 0.0 or to 1 for eliminating repetition in output. We will set ours to 0.5\n",
    "    presence_penalty=0.5  \n",
    ")\n",
    "\n",
    "# Now we grab the response text from the response object output from the completion.create() method\n",
    "# Notice the choices[0].text - this is because the completion.create() method can return multiple choices\n",
    "# Which can be useful for some applications but for our purposes we only want the first choice\n",
    "# For example, if a human were taking the output and choosing the best response then we would want to return all of the choices\n",
    "response_text = response.choices[0].text\n",
    "\n",
    "# Print the response text to the console\n",
    "print(response_text)\n",
    "\n",
    "# Save the response to a text file for later use\n",
    "with open(\"ContentGeneration.txt\", \"w\") as file:\n",
    "    file.write(response_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Summarization\n",
    "Now let's assume that, based on the story created by the AI on the previous task, they want a summary for their marketing department. The customer has asked us to write a formal and informal version of the story that will be given to marketing later on. Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal Summary:\n",
      " Once upon a time, in a far away kingdom, lived a beloved princess named Aurora. To celebrate her birthday, the King and Queen threw a grand banquet with two special guests - Flora and Fauna from the magical realm. Flora presented Aurora with an enchanted rosebush that would never lose its petals until true love found her. Fauna then gave her an old book filled with stories of brave knights on daring adventures to save damsels in distress. Inspired by Fauna's words, Aurora vowed to leave home and find true love while holding onto the rosebush as evidence that it will eventually come when meant to be.\n",
      "Informal Summary:\n",
      " Aurora was an adored princess known for her beauty and kindness. For her birthday, the King and Queen held a grand banquet with two magical fairies as guests. Flora presented Aurora with an enchanted rosebush that would never lose its petals until she found true love. Fauna then gave Aurora a book of brave knights going on adventures to save damsels in distress, inspiring her to leave home in search of true love with the rosebush as proof it will eventually come when meant to be.\n"
     ]
    }
   ],
   "source": [
    "# Since we have already imported our packages we don't need to do it again here\n",
    "# We also don't need to grab our API key again since we already did that above as well\n",
    "\n",
    "\n",
    "# create our story variable to hold the story text we generated before\n",
    "story = response_text.split('Characters and Roles:')[0].strip()\n",
    "\n",
    "# Craft our formal summary prompt using a paragraph instead of a list of rules\n",
    "# Notice how we start with a persona \"expert in summarizing stories\" and then we give the AI a little bit of context about the type of content we want it to generate\n",
    "# Specifically we want it to be a formal summary written in a professional tone suitable for publication\n",
    "# The more context we give the AI the better the output will be\n",
    "prompt_formal = f\"\"\"\n",
    "As an expert in summarizing stories, your task is to provide a concise, yet comprehensive, summary of the text I provide you. Analyze each sentence and paragraph carefully to extract key information or arguments. Your final summary should be written in a professional tone, suitable for publication. Keep it detailed but within a 100-word limit.\n",
    "\n",
    "{story}\n",
    "\n",
    "Formal Summary: <summary goes here>\n",
    "\"\"\"\n",
    "\n",
    "response_formal = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",  \n",
    "  prompt=prompt_formal,  \n",
    "\n",
    "  # Since we are creating a formal summary we want the AI to be less creative so we set the temperature to 0.3\n",
    "  temperature=0.3,  \n",
    "  max_tokens=200,  \n",
    "\n",
    "  # mid-level diversity setting to strike a balance between repetition and creativity\n",
    "  top_p=0.2,  \n",
    "\n",
    "  # use the same frequency and presence penalty settings as before\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "\n",
    "formal_summary = response_formal.choices[0].text.strip().replace(\"Formal Summary:\", \"\").strip()\n",
    "\n",
    "print(\"Formal Summary:\\n\", formal_summary)\n",
    "\n",
    "\n",
    "# Create informal summary\n",
    "prompt_informal = f\"\"\"\n",
    "Hey there, expert story summarizer! I've got a story for you. Your job? Sum it up like you're chatting with a close friend. Go through it line by line, grab all the cool stuff or important points, and spin it into a fun summary. Keep it light and entertaining but don't go over 100 words, alright?\n",
    "\n",
    "{story}\n",
    "\n",
    "Informal Summary: <summary goes here>\n",
    "\"\"\"\n",
    "\n",
    "response_informal = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",  \n",
    "  prompt=prompt_informal,  \n",
    "  temperature=0.9,  \n",
    "  max_tokens=200,  \n",
    "  top_p=1.0,  \n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "\n",
    "informal_summary = response_informal.choices[0].text.strip().replace(\"Informal Summary:\", \"\").strip()\n",
    "\n",
    "print(\"Informal Summary:\\n\", informal_summary)\n",
    "\n",
    "# Save the responses to a text file\n",
    "with open(\"ContentSummarization.txt\", \"w\") as file:\n",
    "    file.write(\"Formal Summary:\\n\" + formal_summary + \"\\n\\n\")\n",
    "    file.write(\"Informal Summary:\\n\" + informal_summary + \"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
