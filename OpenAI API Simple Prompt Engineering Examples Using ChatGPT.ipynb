{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Simple Prompt Engineering Examples Using ChatGPT\n",
    "\n",
    "Welcome! This notebook is meant to show some simple prompt engineering examples for those just getting started in the field. You will play the role of an AI consultant who has been hired by a book company. We will look at four common tasks associated with typical AI consulting and prompt engineering job requirements to get you on the road to becoming an effective developer:\n",
    "\n",
    "- Content Generation\n",
    "- Content Summarization\n",
    "- Language Translation\n",
    "- Content Automation\n",
    "\n",
    "There are a couple of things to consider as we explore these concepts:\n",
    "First, we are limiting ourselves to exclusively using OpenAI's API even though there might be better alternatives out there to keep things easy to implement. \n",
    "Second, You will need an OpenAI API key to do these lessons. They give you a $5 credit when you sign up but IT CAN COST MONEY if you aren't careful. \n",
    "Just be aware of your usage patterns and you will be fine. You can sign up for your API access here: https://platform.openai.com/ \n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Generation\n",
    "Assume we work for a book company and they are looking at expanding into the children book market. They don't want to invest a lot of money in authors before they have tested the waters a bit. That's where we come in; our first task is to write a prompt to create a kids short story. The customer wants us to generate a story and make sure the AI outputs an HTML table with the names of the characters from the story and their role in the story so they can put it up on their website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once upon a time, in a far away kingdom there lived a young princess named Aurora. She was known for her beauty and kindness, and everyone in the kingdom loved her dearly. Despite being the daughter of a powerful king, Aurora had a gentle soul and always showed compassion to those around her. \n",
      "\n",
      "One day, the king and queen decided to throw a grand banquet to celebrate their daughter's birthday. The entire kingdom was invited, but there were two special guests who had been invited – two fairies from the magical realm beyond the castle walls. \n",
      "\n",
      "The first fairy was Flora, an old wise woman with magical powers that could make plants grow with just one touch of her staff. The second fairy was Fauna, a mischievous sprite who delighted in causing trouble among mortals. Despite their differences, they both shared one thing - they were both devoted to Aurora and wanted nothing more than to make her happy on her special day. \n",
      "\n",
      "When the feast began, all eyes were on Aurora as she entered the room with grace and poise befitting a princess. All of the guests marveled at her beauty and wished for her happiness on this day of celebration. However, it soon became apparent that something was wrong - Aurora did not seem happy at all! \n",
      "\n",
      "The King asked what was wrong and Aurora explained that she wanted nothing more than true love but had yet to find it in this kingdom or any other. As she said these words, Flora stepped forward and presented Aurora with an enchanted rosebush that would never lose its petals nor fade in color until true love found her. With tears of joy streaming down their faces, everyone in attendance thanked Flora for such a beautiful gift as they watched Aurora take hold of the rosebush with tender care. \n",
      "\n",
      "Fauna then stepped forward with a mischievous glint in his eyes as he handed Aurora an old book filled with stories about brave knights from distant lands on daring adventures to save damsels in distress - adventures exactly like hers! \n",
      "Aurora opened up the book with curiosity as Fauna whispered into her ear “Your adventure awaits you…” before magically disappearing without another word spoken between them. \n",
      "\n",
      "With newfound courage ignited by Fauna's words ringing through her mind, Aurora vowed to leave home and find true love no matter what challenges lay ahead along the way - all while holding onto the enchanted rosebush given by Flora as evidence that true love will eventually come whenever it is meant to be found.  \n",
      "\n",
      "Characters and Roles: \n",
      "\n",
      " <table>\n",
      "<tr> <th>Character</th> <th>Role</th></tr>\n",
      "<tr><td>Aurora</td><td>Young princess looking for true love.</td></tr>  \n",
      "<tr><td>Flora</td><td>Old wise woman with magical powers.</td></tr>  \t\t\t\t\t\t\t\t\t\t    <tr><td>Fauna</td><td>Mischievous sprite.</td></tr>  \t    <tr><td>King & Queen </td><td>Parents of Princess Aurora.</td></tr>   </table\n"
     ]
    }
   ],
   "source": [
    "# import our packages\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# grab our API key from our environment variables\n",
    "# NOTE: if you don't have an environment variable set, you can just paste your key in directly by modifying the line below and setting your openai_key to your key\n",
    "# like this: openai_key = \"your key goes here\"\n",
    "openai_key = os.getenv('OPENAI_KEY')\n",
    "\n",
    "openai.api_key = openai_key\n",
    "\n",
    "# craft our prompt - this is the text that the AI will use to generate the content\n",
    "# In this example we use the persona feature to give the AI a little bit of context about the type of content we want it to generate\n",
    "# Specifically we want it to be a children story teller generate content in the style of Hans Christian Andersen\n",
    "# This sets the tone and style of the content we want to generate\n",
    "# Next, we give the AI some direction about the type of content we want it to generate to set the \"boundaries\" of the content - these are typically given to us by the client\n",
    "#\n",
    "# Now we deal with the output\n",
    "# We clearly indicate where the story should go and where the character and role table should go to make it easy to parse out the content\n",
    "prompt = \"\"\"\n",
    "Act as a children story teller in the style of Hans Christian Andersen using the following process:\n",
    "1. Make the story no more than 1000 words.\n",
    "2. Create a story that begins with an opening scene that captures the reader's imagination. \n",
    "3. Set the scene by providing a detailed description of the setting and atmosphere, including the time of day, the weather, and any other relevant details that help to immerse the reader in the story. \n",
    "4. Introduce the minor characters in the story, providing enough detail about each character to make them interesting and memorable. \n",
    "5. Introduce the main character of the story, describing their physical appearance in detail and giving some insight into their personality and motivations. \n",
    "6. Make sure that the story has a clear plot and a satisfying resolution, and that the themes explored in the story are appropriate for a young audience. \n",
    "7. Finally, be sure to use vivid language and imagery to bring the story to life and engage the reader's imagination. \n",
    "\n",
    "The story can be about anything you want. Be creative!\n",
    "\n",
    "When you have given me the story, then produce a HTML table with the names of the characters from the story and their role in the story.\n",
    "\n",
    "Story: <story goes here>\n",
    "\n",
    "Characters and Roles: <HTML table goes here>\n",
    "\n",
    "\"\"\"\n",
    "# Now we use the completion.create() method to generate the content and things really get interesting. See my comments on each of the parameters below\n",
    "response = openai.Completion.create(\n",
    "    # This is the model we want to use to generate the content - in this case we are using a ChatGPT 3.5 model because it is cheaper to use than the GPT-4 model\n",
    "    # Useful for prototyping and testing then using the GPT-4 model for later iterations\n",
    "    # At the time of this writing, for input the GPT-3.5 model costs $0.0015 per 1000 tokens and the GPT-4 model costs $0.03 per 1000 tokens; for output the \n",
    "    # GPT-3.5 model costs $0.002 per 1000 tokens and the GPT-4 model costs $0.06 per 1000 tokens\n",
    "    # Quite a cost differential between the two models so start cheap to prototype and test and then use the GPT-4 model for later on\n",
    "    model=\"text-davinci-003\",  \n",
    "\n",
    "    # This is the prompt we created above\n",
    "    prompt=prompt,  \n",
    "\n",
    "    # This is the temperature parameter - it controls the randomness of the output or, put another way, how \"creative\" the AI is\n",
    "    # The number can be between 0 and 1 - the closer to 0 the less \"creative\" the AI is and as the number approaches 1 the more \"creative\" the AI is\n",
    "    # Since we are creating children's stories we want the AI to be more creative so we set the temperature to 0.7\n",
    "    # If we were creating something like a legal document we would want the AI to be less creative so we would set the temperature to 0.2 for example\n",
    "    temperature=0.7,  \n",
    "\n",
    "    # This is the max_tokens parameter - it controls the length of the output\n",
    "    # To quote OpenAI: \"You can think of tokens as pieces of words, where 1,000 tokens is about 750 words.\"\n",
    "    # Our prompt is 1000 words so we set the max_tokens to 2000 to give the AI enough room to generate the content\n",
    "    # But small enough to keep the cost down\n",
    "    max_tokens=2000,  \n",
    "\n",
    "    # This is the top_p parameter - it controls the range of words chosen for the output\n",
    "    # The values are from 0 to 1 - the closer to 0 the less diverse the output and the closer to 1 the more diverse the output\n",
    "    # For example, if we set top_p to 0.5 then the AI will only use the top 50% of the most likely words\n",
    "    # But, if we set top_p to 1.0 then the AI will use all of the words\n",
    "    # Since we are creating children's stories we want the AI to be more diverse so we set the top_p to 1.0\n",
    "    # If we were creating something like a legal document we would want the AI to be less diverse so we would set the top_p to 0.5 or less, for example\n",
    "    top_p=1.0,  \n",
    "\n",
    "    # This is the frequency_penalty parameter - this parameter is used to discourage the model from repeating the same words or phrases too frequently within the generated text.\n",
    "    # A higher frequency_penalty value will result in the model being more conservative in its use of repeated words. \n",
    "    # The values are from -2.0 to 2.0 - the closer to -2.0 the more likely the AI will repeat the same words and the closer to 2.0 the less likely the AI will repeat the same words\n",
    "    # Typical setting for this parameter is 0.0 or to 1 for eliminating repetition in output. We will set ours to 0.5\n",
    "    frequency_penalty=0.5,  \n",
    "\n",
    "    # This is the presence_penalty parameter - this parameter is used to encourage the model to include a diverse range of words in the generated text. \n",
    "    # A higher presence_penalty value will result in the model being more likely to generate words that have not yet been included in the generated text.\n",
    "    # The values are from -2.0 to 2.0 - the closer to -2.0 the more likely the AI will repeat the same words and the closer to 2.0 the more likely to include words not used before\n",
    "    # As with the frequency_penalty parameter, typical setting for this parameter is 0.0 or to 1 for eliminating repetition in output. We will set ours to 0.5\n",
    "    presence_penalty=0.5  \n",
    ")\n",
    "\n",
    "# Now we grab the response text from the response object output from the completion.create() method\n",
    "# Notice the choices[0].text - this is because the completion.create() method can return multiple choices\n",
    "# Which can be useful for some applications but for our purposes we only want the first choice\n",
    "# For example, if a human were taking the output and choosing the best response then we would want to return all of the choices\n",
    "response_text = response.choices[0].text\n",
    "\n",
    "# Print the response text to the console\n",
    "print(response_text)\n",
    "\n",
    "# Save the response to a text file for later use\n",
    "with open(\"ContentGeneration.txt\", \"w\") as file:\n",
    "    file.write(response_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Summarization\n",
    "Now let's assume that, based on the story created by the AI on the previous task, they want a summary for their marketing department. The customer has asked us to write a formal and informal version of the story that will be given to marketing later on. Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal Summary:\n",
      " Once upon a time, in a far away kingdom, lived a beloved princess named Aurora. To celebrate her birthday, the King and Queen threw a grand banquet with two special guests - Flora and Fauna from the magical realm. Flora presented Aurora with an enchanted rosebush that would never lose its petals until true love found her. Fauna then gave her an old book filled with stories of brave knights on daring adventures to save damsels in distress. Inspired by Fauna's words, Aurora vowed to leave home and find true love while holding onto the rosebush as evidence that it will eventually come when meant to be.\n",
      "Informal Summary:\n",
      " Once upon a time, in a far away kingdom, there lived a beautiful and kind princess named Aurora. To celebrate her birthday, the King and Queen threw a grand banquet and invited two special guests - two fairies from the magical realm. Everyone marveled at Aurora's beauty, but she was not truly happy. Thankfully, the wise old fairy Flora presented her with an enchanted rosebush that would remain in bloom until true love was found. The mischievous fairy Fauna also gave her a book filled with stories of brave knights, inspiring Aurora to embark on her own journey to find true love. With newfound courage and the promise of the rosebush, Aurora was determined to find her happily ever after.\n"
     ]
    }
   ],
   "source": [
    "# Since we have already imported our packages we don't need to do it again here\n",
    "# We also don't need to grab our API key again since we already did that above as well\n",
    "\n",
    "\n",
    "# Create our story variable to hold the story text we generated before\n",
    "story = response_text.split('Characters and Roles:')[0].strip()\n",
    "\n",
    "# Craft our formal summary prompt using a paragraph instead of a list of rules\n",
    "# Notice how we start with a persona \"expert in summarizing stories\" and then we give the AI a little bit of context about the type of content we want it to generate\n",
    "# Specifically we want it to be a formal summary written in a professional tone suitable for publication\n",
    "# The more context we give the AI the better the output will be\n",
    "prompt_formal = f\"\"\"\n",
    "As an expert in summarizing stories, your task is to provide a concise, yet comprehensive, summary of the text I provide you. Analyze each sentence and paragraph carefully to extract key information or arguments. Your final summary should be written in a professional tone, suitable for publication. Keep it detailed but within a 100-word limit.\n",
    "\n",
    "{story}\n",
    "\n",
    "Formal Summary: <summary goes here>\n",
    "\"\"\"\n",
    "\n",
    "response_formal = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",  \n",
    "  prompt=prompt_formal,  \n",
    "\n",
    "  # Since we are creating a formal summary we want the AI to be less creative so we set the temperature to 0.3\n",
    "  temperature=0.3,  \n",
    "  max_tokens=200,  \n",
    "\n",
    "  # Low diversity setting to use the most likely words in our formal summary \n",
    "  top_p=0.2,  \n",
    "\n",
    "  # Use the same frequency and presence penalty settings as before\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "\n",
    "formal_summary = response_formal.choices[0].text.strip().replace(\"Formal Summary:\", \"\").strip()\n",
    "\n",
    "print(\"Formal Summary:\\n\", formal_summary)\n",
    "\n",
    "\n",
    "# Craft our informal summary prompt using a paragraph instead of a list of rules as well\n",
    "# Right out of the gate notice that we use and informal tone in the prompt\n",
    "# Then we start, as we always do, with a persona; in this case \"expert story summarizer\"\n",
    "# Finally, we give the AI a little bit of context about the type of content we want it to generate\n",
    "# Specifically we want it to be a informal summary \"chatting with a close friend\" written in a casual tone tone\n",
    "# The more context we give the AI the better the output will be\n",
    "prompt_informal = f\"\"\"\n",
    "Hey there, expert story summarizer! I've got a story for you. Your job? Sum it up like you're chatting with a close friend. Go through it line by line, grab all the cool stuff or important points, and spin it into a fun summary. Keep it light and entertaining but don't go over 100 words, alright?\n",
    "\n",
    "{story}\n",
    "\n",
    "Informal Summary: <summary goes here>\n",
    "\"\"\"\n",
    "\n",
    "response_informal = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",  \n",
    "  prompt=prompt_informal,  \n",
    "  temperature=0.8,  # high temperature setting to make the AI more creative\n",
    "  max_tokens=200,   # plenty of tokens to hold the informal summary\n",
    "  top_p=1.0,        # high diversity setting to use all of the words in our informal summary\n",
    "  frequency_penalty=0.1, # slightly lower presence frequency to allow for some repetition but not too much (i.e. \"far, far, away\")\n",
    "  presence_penalty=0.1   # slightly lower presence penalty to allow for fewer unique words but not too few (i.e. \"far, far, away\")\n",
    ")\n",
    "\n",
    "informal_summary = response_informal.choices[0].text.strip().replace(\"Informal Summary:\", \"\").strip()\n",
    "\n",
    "print(\"Informal Summary:\\n\", informal_summary)\n",
    "\n",
    "# Save the responses to text files \n",
    "with open(\"ContentSummarization.txt\", \"w\") as file:\n",
    "    file.write(\"Formal Summary:\\n\" + formal_summary + \"\\n\\n\")\n",
    "    file.write(\"Informal Summary:\\n\" + informal_summary + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Translation\n",
    "Let's take it a step further. Now, the marketing team wants to take your summaries and translate them into Spanish, French, and German for their international markets. To make things more interesting, they have asked for the information in JSON format to give to their developers for easy consumption. We will take both summaries and produce translations that can be used by their development team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"formal_translations\": {\"Spanish\": \"Una vez, en un reino lejano, viv\\u00eda una amada princesa llamada Aurora. Para celebrar su cumplea\\u00f1os, el Rey y la Reina organizaron un gran banquete con dos invitados especiales: Flora y Fauna del reino m\\u00e1gico. Flora present\\u00f3 a Aurora con un arbusto encantado que nunca perder\\u00eda sus p\\u00e9talos hasta que el verdadero amor la encontrara. Fauna luego le dio un viejo libro lleno de historias de valientes caballeros en aventuras audaces para salvar damiselas en apuros. Inspirada por las palabras de Fauna, Aurora se comprometi\\u00f3 a salir de casa y encontrar el verdadero amor mientras manten\\u00eda\", \"French\": \"Il \\u00e9tait une fois, dans un royaume lointain, vivait une princesse bien-aim\\u00e9e nomm\\u00e9e Aurora. Pour c\\u00e9l\\u00e9brer son anniversaire, le Roi et la Reine organis\\u00e8rent un grand banquet avec deux invit\\u00e9s sp\\u00e9ciaux - Flora et Fauna du royaume magique. Flora pr\\u00e9senta \\u00e0 Aurora un buisson de roses enchant\\u00e9 qui ne perdrait jamais ses p\\u00e9tales jusqu'\\u00e0 ce que le vrai amour la trouve. Fauna lui donna alors un vieux livre rempli d'histoires de chevaliers courageux partant \\u00e0 l'aventure pour sauver des demoiselles en d\\u00e9tresse. Inspir\\u00e9e par les mots de Fauna, Aurora s'engagea \\u00e0 quitter sa maison\", \"German\": \"Einst, in einem fernen K\\u00f6nigreich, lebte eine geliebte Prinzessin namens Aurora. Um ihren Geburtstag zu feiern, warfen der K\\u00f6nig und die K\\u00f6nigin ein gro\\u00dfes Bankett mit zwei besonderen G\\u00e4sten - Flora und Fauna aus dem magischen Reich. Flora schenkte Aurora einen verzauberten Rosenstrauch, der niemals seine Bl\\u00fctenbl\\u00e4tter verlieren w\\u00fcrde, bis wahre Liebe sie finden w\\u00fcrde. Fauna gab ihr dann ein altes Buch voller Geschichten von tapferen Rittern auf mutigen Abenteuern, um Damen in Not zu retten. Inspiriert von Faunas Worten schw\"}, \"informal_translations\": {\"Spanish\": \"Una vez, en un reino lejano, viv\\u00eda una hermosa y amable princesa llamada Aurora. Para celebrar su cumplea\\u00f1os, el Rey y la Reina organizaron un gran banquete e invitaron a dos invitados especiales: dos hadas del reino m\\u00e1gico. Todos se maravillaron de la belleza de Aurora, pero ella no estaba verdaderamente feliz. Afortunadamente, la sabia vieja hada Flora le present\\u00f3 un arbusto encantado que permanecer\\u00eda en flor hasta que encontrara el verdadero amor. La traviesa hada Fauna tambi\\u00e9n le dio un libro lleno de historias de valientes caballeros, inspirando a Aurora a\", \"French\": \"Il \\u00e9tait une fois, dans un royaume lointain, vivait une belle et gentille princesse nomm\\u00e9e Aurora. Pour c\\u00e9l\\u00e9brer son anniversaire, le Roi et la Reine organis\\u00e8rent un grand banquet et invit\\u00e8rent deux invit\\u00e9s sp\\u00e9ciaux - deux f\\u00e9es du royaume magique. Tout le monde admirait la beaut\\u00e9 d'Aurora, mais elle n'\\u00e9tait pas vraiment heureuse. Heureusement, la sage vieille f\\u00e9e Flora lui pr\\u00e9senta un buisson enchant\\u00e9 qui resterait en fleurs jusqu'\\u00e0 ce que le vrai amour soit trouv\\u00e9. La f\\u00e9e malicieuse Fauna lui donna \\u00e9galement un livre rempli d'histoires de chevaliers\", \"German\": \"Einst, in einem fernen K\\u00f6nigreich, lebte eine sch\\u00f6ne und freundliche Prinzessin namens Aurora. Um ihren Geburtstag zu feiern, warfen der K\\u00f6nig und die K\\u00f6nigin ein gro\\u00dfes Bankett und luden zwei besondere G\\u00e4ste ein - zwei Feen aus dem magischen Reich. Alle staunten \\u00fcber Auroras Sch\\u00f6nheit, aber sie war nicht wirklich gl\\u00fccklich. Zum Gl\\u00fcck schenkte ihr die weise alte Fee Flora einen verzauberten Rosenstrauch, der bl\\u00fchen w\\u00fcrde, bis wahre Liebe gefunden wurde. Die verspielte Fee Fauna schenkte ihr auch ein Buch voller Ges\"}}\n"
     ]
    }
   ],
   "source": [
    "# Since we have already imported our packages we don't need to do it again here\n",
    "# We also don't need to grab our API key again since we already did that above as well\n",
    "\n",
    "# We do need to add the json package to our imports though\n",
    "import json\n",
    "\n",
    "# Create a list of languages to translate\n",
    "# Feel free to add or remove languages as you see fit\n",
    "# I suggest you stick to latin based languages for now as they are easier to translate\n",
    "languages = ['Spanish', 'French', 'German']\n",
    "\n",
    "# Create variables (dictionaries) to hold the translations\n",
    "formal_translations = {}\n",
    "informal_translations = {}\n",
    "\n",
    "# Loop through the languages and translate the formal and informal summaries\n",
    "for language in languages:\n",
    "    \n",
    "    # Start with the formal summary\n",
    "    # Remember we are grabbing our summary from the previous cell\n",
    "    prompt_formal = f\"\"\"\n",
    "    Translate the following English text to {language}:\n",
    "\n",
    "    {formal_summary}\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the creation parameters\n",
    "    response_formal = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt_formal,\n",
    "      temperature=0.3, # use a low temperature setting to make the AI less creative while allowing for a little nuance in some languages\n",
    "      max_tokens=200,\n",
    "      top_p=0.3,  # use a low diversity setting to use the most likely words in our formal summary\n",
    "      frequency_penalty=0.5, \n",
    "      presence_penalty=0.5  \n",
    "    )\n",
    "\n",
    "    # Add it to our dictionary of formal translations with the language as the key\n",
    "    formal_translation = response_formal.choices[0].text.strip()\n",
    "    formal_translations[language] = formal_translation\n",
    "\n",
    "    # Translate informal summary\n",
    "    prompt_informal = f\"\"\"\n",
    "    Translate the following English text to {language}:\n",
    "\n",
    "    {informal_summary}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the creation parameters the same as for formal translation\n",
    "    # We don't want creativity here, we want a direct translation\n",
    "    # The time to be creative was when we created the informal summary\n",
    "    response_informal = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt_informal,\n",
    "      temperature=0.3,\n",
    "      max_tokens=200,\n",
    "      top_p=0.3,  \n",
    "      frequency_penalty=0.5, \n",
    "      presence_penalty=0.5  \n",
    "    )\n",
    "\n",
    "    # Add it to our dictionary of informal translations with the language as the key\n",
    "    informal_translation = response_informal.choices[0].text.strip()\n",
    "    informal_translations[language] = informal_translation\n",
    "\n",
    "# Now that the loop is done, convert the dictionaries to JSON\n",
    "translations_json = json.dumps({\n",
    "    \"formal_translations\": formal_translations,\n",
    "    \"informal_translations\": informal_translations,\n",
    "})\n",
    "\n",
    "# Print the result\n",
    "print(translations_json)\n",
    "\n",
    "# Write JSON string to a file\n",
    "with open('LanguageTranslation.json', 'w') as f:\n",
    "    f.write(translations_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Automation\n",
    "The business loves your output so far and asks for one last thing: dealing with their product reviews. They need an AI agent to write a customer service email response addressing the client's review. Also, they want the agent to create action items as suggestions for the company to take based on the review. Another dev team is making the function that takes your output (review, response, and action items) and processes it for use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Review: Z-Dawg Margarita Maker\n",
    "\n",
    "I recently had the opportunity to try out the Z-Dawg Margarita Maker and I'd like to share my detailed review of this product. During the month of November, I was thrilled to discover that the 17-piece system was on a seasonal sale, priced at a mere $49, which was nearly half off the original price. However, my excitement was short-lived when, around the second week of December, the prices skyrocketed to around $70-$89 for the same system, leaving me a bit puzzled and skeptical about the sudden price increase.\n",
    "\n",
    "In terms of design and build quality, the Z-Dawg Margarita Maker has an overall appealing look. However, upon closer examination, I noticed that the part where the blade locks into place doesn't appear as robust as in previous editions released a few years ago. Despite this observation, I intend to handle the blender with utmost care, especially since I use it to crush ice. My blending technique involves initially pulverizing these items in the blender. Similarly, when preparing smoothies, which the product advertises it can also do, I utilize the cross-cutting blade initially and then switch to the flat blade if I prefer a smoother and less pulpy texture.\n",
    "\n",
    "For those who enjoy making smoothies, I have a helpful tip to share. It's best to finely cut and freeze the fruits and vegetables before blending them. This way, you can reduce the amount of ice needed while still achieving a delicious and refreshing smoothie. In the case of making sorbet, I've found that using a small to medium-sized food processor yields excellent results.\n",
    "\n",
    "After approximately a year of regular use, I did encounter a minor issue with the Z-Dawg Margarita Maker. The motor started making an unusual noise, prompting me to reach out to customer service. Unfortunately, I discovered that the warranty had already expired, requiring me to purchase a new blender. It's worth noting that the overall quality of similar products in the market seems to have declined over time. Manufacturers seem to rely on brand recognition and consumer loyalty to maintain sales, rather than consistently improving the product's durability.\n",
    "\n",
    "On a positive note, the delivery service for the Z-Dawg Margarita Maker was commendable. I received the product within just two days of placing my order, which exceeded my expectations and demonstrated excellent customer service.\n",
    "\n",
    "In conclusion, the Z-Dawg Margarita Maker offers satisfactory performance and functionality, despite some concerns about the build quality. The fluctuating prices during the sales period are a noteworthy aspect to consider, as it raises questions about fair pricing practices. Given my experience with the motor issue and the general decline in product quality, I recommend potential buyers thoroughly evaluate their options before making a purchase decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "\n",
      "Product Review: Z-Dawg Margarita Maker\n",
      "\n",
      "I recently had the opportunity to try out the Z-Dawg Margarita Maker and I'd like to share my detailed review of this product. During the month of November, I was thrilled to discover that the 17-piece system was on a seasonal sale, priced at a mere $49, which was nearly half off the original price. However, my excitement was short-lived when, around the second week of December, the prices skyrocketed to around $70-$89 for the same system, leaving me a bit puzzled and skeptical about the sudden price increase.\n",
      "\n",
      "In terms of design and build quality, the Z-Dawg Margarita Maker has an overall appealing look. However, upon closer examination, I noticed that the part where the blade locks into place doesn't appear as robust as in previous editions released a few years ago. Despite this observation, I intend to handle the blender with utmost care, especially since I use it to crush ice. My blending technique involves initially pulverizing these items in the blender. Similarly, when preparing smoothies, which the product advertises it can also do, I utilize the cross-cutting blade initially and then switch to the flat blade if I prefer a smoother and less pulpy texture.\n",
      "\n",
      "For those who enjoy making smoothies, I have a helpful tip to share. It's best to finely cut and freeze the fruits and vegetables before blending them. This way, you can reduce the amount of ice needed while still achieving a delicious and refreshing smoothie. In the case of making sorbet, I've found that using a small to medium-sized food processor yields excellent results.\n",
      "\n",
      "After approximately a year of regular use, I did encounter a minor issue with the Z-Dawg Margarita Maker. The motor started making an unusual noise, prompting me to reach out to customer service. Unfortunately, I discovered that the warranty had already expired, requiring me to purchase a new blender. It's worth noting that the overall quality of similar products in the market seems to have declined over time. Manufacturers seem to rely on brand recognition and consumer loyalty to maintain sales, rather than consistently improving the product's durability.\n",
      "\n",
      "On a positive note, the delivery service for the Z-Dawg Margarita Maker was commendable. I received the product within just two days of placing my order, which exceeded my expectations and demonstrated excellent customer service.\n",
      "\n",
      "In conclusion, the Z-Dawg Margarita Maker offers satisfactory performance and functionality, despite some concerns about the build quality. The fluctuating prices during the sales period are a noteworthy aspect to consider, as it raises questions about fair pricing practices. Given my experience with the motor issue and the general decline in product quality, I recommend potential buyers thoroughly evaluate their options before making a purchase decision.\n",
      "\n",
      "Response:\n",
      "Thank you for taking the time to provide us with your feedback about our product. We are sorry to hear that it did not meet your expectations. We strive to provide quality products and customer service, so we take all reviews seriously. We would like to understand more about what went wrong and how we can improve our product in the future. Please do not hesitate to reach out if you need any help or have any questions.\n",
      "\n",
      "Action Items:\n",
      "- Investigate customer's experience with the product\n",
      "- Review customer service process for this situation \n",
      "- Create a plan of action to address customer's concerns \n",
      "- Develop a strategy for improved customer satisfaction \n",
      "- Train customer service agents on how to respond effectively to negative reviews\n"
     ]
    }
   ],
   "source": [
    "# Since we have already imported our packages we don't need to do it again here\n",
    "# We also don't need to grab our API key again since we already did that above as well\n",
    "# If you want to run this as a \"stand alone\" script then you will need to import the packages and grab the API key again\n",
    "\n",
    "# create a variable to hold our review\n",
    "review = \"\"\"\n",
    "Product Review: Z-Dawg Margarita Maker\n",
    "\n",
    "I recently had the opportunity to try out the Z-Dawg Margarita Maker and I'd like to share my detailed review of this product. During the month of November, I was thrilled to discover that the 17-piece system was on a seasonal sale, priced at a mere $49, which was nearly half off the original price. However, my excitement was short-lived when, around the second week of December, the prices skyrocketed to around $70-$89 for the same system, leaving me a bit puzzled and skeptical about the sudden price increase.\n",
    "\n",
    "In terms of design and build quality, the Z-Dawg Margarita Maker has an overall appealing look. However, upon closer examination, I noticed that the part where the blade locks into place doesn't appear as robust as in previous editions released a few years ago. Despite this observation, I intend to handle the blender with utmost care, especially since I use it to crush ice. My blending technique involves initially pulverizing these items in the blender. Similarly, when preparing smoothies, which the product advertises it can also do, I utilize the cross-cutting blade initially and then switch to the flat blade if I prefer a smoother and less pulpy texture.\n",
    "\n",
    "For those who enjoy making smoothies, I have a helpful tip to share. It's best to finely cut and freeze the fruits and vegetables before blending them. This way, you can reduce the amount of ice needed while still achieving a delicious and refreshing smoothie. In the case of making sorbet, I've found that using a small to medium-sized food processor yields excellent results.\n",
    "\n",
    "After approximately a year of regular use, I did encounter a minor issue with the Z-Dawg Margarita Maker. The motor started making an unusual noise, prompting me to reach out to customer service. Unfortunately, I discovered that the warranty had already expired, requiring me to purchase a new blender. It's worth noting that the overall quality of similar products in the market seems to have declined over time. Manufacturers seem to rely on brand recognition and consumer loyalty to maintain sales, rather than consistently improving the product's durability.\n",
    "\n",
    "On a positive note, the delivery service for the Z-Dawg Margarita Maker was commendable. I received the product within just two days of placing my order, which exceeded my expectations and demonstrated excellent customer service.\n",
    "\n",
    "In conclusion, the Z-Dawg Margarita Maker offers satisfactory performance and functionality, despite some concerns about the build quality. The fluctuating prices during the sales period are a noteworthy aspect to consider, as it raises questions about fair pricing practices. Given my experience with the motor issue and the general decline in product quality, I recommend potential buyers thoroughly evaluate their options before making a purchase decision.\n",
    "\"\"\"\n",
    "\n",
    "# create a variable to hold our prompt\n",
    "prompt = f\"\"\"\n",
    "As a customer service agent, your task is to respond to a customer's product review. The response should be professional and friendly, while showing empathy to make the customer feel heard and valued. Your reply should be 2-3 paragraphs long.\n",
    "\n",
    "After the customer response, please list 2-5 action items that the company should consider to address the issues mentioned in the review. Use bullet points for the action items.\n",
    "\n",
    "Your output should look like this:\n",
    "\n",
    "\n",
    "Response: <put response here>\n",
    "\n",
    "Action Items: <put action items here>\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0.6, # keep it between 0.4 to 0.6 to balance creativity with coherence\n",
    "  max_tokens=300,\n",
    "  top_p=0.7, # allowing for some diversity in the response\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5 \n",
    ")\n",
    "\n",
    "# Remove leading and trailing white spaces from the response text\n",
    "response_text = response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "# Find the position of the \"Action Items:\" keyword in the text\n",
    "action_items_start = response_text.find(\"Action Items:\")\n",
    "\n",
    "\n",
    "# Extract the response to the customer by taking all text before \"Action Items:\"\n",
    "response_to_customer = response_text[:action_items_start].replace(\"Response:\", \"\").strip()\n",
    "\n",
    "# Extract the action items by taking all text after \"Action Items:\"\n",
    "action_items = response_text[action_items_start + len(\"Action Items:\"):].strip()\n",
    "\n",
    "# Print the separated responses remembering to add the original review to the output\n",
    "print(\"Review:\")\n",
    "print(review)\n",
    "print(\"Response:\")\n",
    "print(response_to_customer)\n",
    "print(\"\\nAction Items:\")\n",
    "print(action_items)\n",
    "\n",
    "\n",
    "# Save the responses to a text file\n",
    "with open(\"ContentAutomation.txt\", \"w\") as file:\n",
    "    file.write(\"Review:\\n\" + review + \"\\n\\n\")\n",
    "    file.write(\"Response:\\n\" + response_to_customer + \"\\n\\n\")\n",
    "    file.write(\"Action Items:\\n\" + action_items + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! If you made it this far you have the basic skills needed to start your journey down the road of AI prompt engineering and consulting. Good luck and drop me an email if you have any suggestions / comments. Make sure to use your skills as much as possible. Using AI every day will make you better faster. \n",
    "\n",
    "# Welcome to the AI revolution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
